# ğŸ“¦ vdb-accel-lab

> **Vector Database Acceleration Lab**: Reproducible benchmarks to measure and prove DBPU acceleration potential

## ğŸ¯ Purpose

This repository is part of DataStream's DBPU (Database Processing Unit) development stack:
- **vdb-accel-lab** â† You are here (benchmarking & workload generation)
- **milvus-dbpu-plugin** (profiling hooks & intelligence)
- **dbpu-runtime** (hardware offload layer)

The goal is to measure the acceleration potential of offloading vector database operations (specifically FAISS scan_codes bottleneck) to custom hardware.

---

## ğŸ“ Repository Structure
```
vdb-accel-lab/
â”œâ”€â”€ workloads/              # Workload generation
â”‚   â””â”€â”€ lab_gen.py         # Smart workload generator (auto-detects Milvus)
â”œâ”€â”€ analyzer/              # Analysis & visualization tools
â”‚   â”œâ”€â”€ visualize.py       # Performance visualization & comparison
â”‚   â”œâ”€â”€ analyze_hooks.py   # C++ profiling hook analysis
â”‚   â”œâ”€â”€ calculate_roi.py   # Business ROI calculator
â”‚   â””â”€â”€ export_metrics.py  # Prometheus metrics exporter
â”œâ”€â”€ dashboards/            # Grafana dashboards (future)
â”œâ”€â”€ docs/                  # Documentation
â”‚   â””â”€â”€ SETUP.md          # Home/remote setup guide
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Milvus 2.4+ (optional - will use mock mode if unavailable)
- Docker (optional, for local Milvus)

### Installation
```bash
# Clone the repository
git clone https://github.com/DatabaseProcessor/vdb-accel-lab.git
cd vdb-accel-lab

# Setup virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ§ª Usage

### 1. Generate Workload Data

The workload generator **automatically detects** if Milvus is available:
- âœ… **Milvus available** â†’ Runs real vector searches
- ğŸ­ **Milvus unavailable** â†’ Uses mock mode with realistic timings
```bash
# Run workload (auto-detects Milvus)
python workloads/lab_gen.py

# For remote Milvus
MILVUS_HOST=192.168.1.15 python workloads/lab_gen.py

# Check generated logs
tail -f /tmp/dbpu-knowhere.jsonl
```

**Output:**
```
âœ… Milvus detected - Running in REAL mode
ğŸš€ DBPU Acceleration Lab - Smart Workload Generator
   Mode: REAL

Setting up real Milvus collection...
Inserting 10000 vectors (dim=128)...
âœ… Real data inserted

============================================================
Testing: HNSW_Normal (HNSW)
============================================================
Creating index: {'M': 16, 'efConstruction': 200}
âœ… Latency: 57.63 ms (REAL)
...
```

### 2. Visualize Performance
```bash
# Generate visual analysis
python analyzer/visualize.py
```

**Output:**
```
ğŸ“Š DBPU ACCELERATION POTENTIAL ANALYSIS
================================================================================
Mode: REAL
Time: 2026-02-11T10:01:10.483979
Total tests: 3

ğŸ“ˆ Performance Comparison
--------------------------------------------------------------------------------
Index Type      Label                Latency (ms)    Bar Chart
--------------------------------------------------------------------------------
HNSW            HNSW_Normal               57.63      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
IVF_FLAT        IVF_Normal               117.91      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
FLAT            Flat_Scan                299.28      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

ğŸš€ Acceleration Potential
--------------------------------------------------------------------------------
Baseline (FLAT scan):         299.28 ms

ğŸ’¡ DBPU Acceleration Scenarios:
   10x DBPU acceleration â†’ FLAT would be ~29.93ms
      â†’ 1.93x better than current best!
   20x DBPU acceleration â†’ FLAT would be ~14.96ms
      â†’ 3.85x better than current best!

ğŸ’° Market opportunity: FLAT scan has 5.19x room for improvement
```

### 3. Analyze C++ Profiling Hooks

Analyzes detailed FAISS operation timings (scan_codes bottleneck):
```bash
python analyzer/analyze_hooks.py
```

**Output:**
```
ğŸ”¬ FAISS OPERATION BREAKDOWN (C++ Profiling)
================================================================================

Index Type      Avg Total (ms)     Avg scan_codes (ms)     % of Total   Bottleneck?
--------------------------------------------------------------------------------
FLAT                  300.00               285.00             95.0%      ğŸ”¥ YES
IVF_FLAT              120.00                95.00             79.2%      ğŸ”¥ YES
HNSW                   50.00                 5.00             10.0%      âœ… No

ğŸš€ DBPU ACCELERATION POTENTIAL

FLAT Analysis:
Current Performance:  300.00ms
scan_codes Time:      285.00ms (95.0%)
ğŸ¯ HIGH PRIORITY - scan_codes is the bottleneck!
   10x DBPU â†’ 43.50ms (overall 6.90x speedup)
   20x DBPU â†’ 29.25ms (overall 10.26x speedup)
```

### 4. Calculate Business ROI
```bash
python analyzer/calculate_roi.py
```

**Output:**
```
ğŸ“ˆ PERFORMANCE ROI ANALYSIS
================================================================================

FLAT:
  Current:        300.00ms per query
  With 10x DBPU:   43.50ms per query (6.90x faster)
  Throughput:      6.90x more queries/second

ğŸ’° INFRASTRUCTURE COST SAVINGS
================================================================================
Current Infrastructure:
  100 GPU servers Ã— $30,000/year = $3,000,000/year

With DBPU (5x speedup):
  20 DBPU servers Ã— $40,000/year = $800,000/year

ğŸ’µ Annual Savings: $2,200,000/year (73.3% reduction)
ğŸ“Š 3-Year Savings: $6,600,000

ğŸŒ MARKET OPPORTUNITY
  â€¢ TAM: $300M (vector database acceleration market)
  â€¢ Revenue (Year 3): $15M - $60M
  â€¢ Exit Value: $500M - $1B
  â€¢ Investor Returns: 12-24x
```

### 5. Export Prometheus Metrics

Start metrics exporter for Grafana/Prometheus integration:
```bash
# Start exporter (runs on port 9090)
python analyzer/export_metrics.py

# Check metrics
curl http://localhost:9090/metrics

# View dashboard
open http://localhost:9090/
```

**Prometheus Configuration:**
```yaml
scrape_configs:
  - job_name: 'dbpu'
    static_configs:
      - targets: ['localhost:9090']
```

**Sample Metrics:**
```
# HELP dbpu_search_latency_ms Average search latency in milliseconds
# TYPE dbpu_search_latency_ms gauge
dbpu_search_latency_ms{index_type="FLAT"} 300.00
dbpu_search_latency_ms{index_type="IVF_FLAT"} 120.00
dbpu_search_latency_ms{index_type="HNSW"} 50.00

# HELP dbpu_acceleration_potential Potential speedup with 10x DBPU
# TYPE dbpu_acceleration_potential gauge
dbpu_acceleration_potential{index_type="FLAT"} 6.90
dbpu_acceleration_potential{index_type="IVF_FLAT"} 4.21
```

---

## ğŸ”¬ What Gets Measured

### Workload Generator (`lab_gen.py`)
- **Python-side latency**: End-to-end search time from client perspective
- **Index types**: HNSW, IVF_FLAT, FLAT (full scan)
- **Workload parameters**: 10K vectors, 128 dimensions, 10 queries per test

### Hook Analyzer (`analyze_hooks.py`)
- **C++ profiling data**: Detailed FAISS internal timings
- **scan_codes bottleneck**: Time spent in distance computation hotspot
- **Bottleneck percentage**: Which indexes are dominated by scan_codes
- **Acceleration potential**: Projected speedup with DBPU offload

### ROI Calculator (`calculate_roi.py`)
- **Performance gains**: Throughput improvements (queries/sec)
- **Cost savings**: Infrastructure reduction (GPU â†’ DBPU migration)
- **Market opportunity**: TAM analysis for vector DB acceleration
- **Investment returns**: Revenue projections and exit multiples

---

## ğŸ“Š Complete Workflow
```bash
# 1. Generate benchmark data
python workloads/lab_gen.py

# 2. Visualize performance comparison
python analyzer/visualize.py

# 3. Analyze C++ profiling hooks
python analyzer/analyze_hooks.py

# 4. Calculate business case
python analyzer/calculate_roi.py

# 5. Export metrics for monitoring
python analyzer/export_metrics.py &

# 6. View real-time metrics
curl http://localhost:9090/metrics
```

---

## ğŸ  Remote/Home Setup

If your office and home computers are on the same network:
```bash
# On office computer (find IP)
ipconfig getifaddr en0  # Mac WiFi
# Example output: 192.168.1.15

# On home computer (connect)
export MILVUS_HOST=192.168.1.15
python workloads/lab_gen.py
```

See [docs/SETUP.md](docs/SETUP.md) for detailed remote setup instructions.

---

## ğŸ¯ Development Roadmap

### Phase 1: Benchmarking (Current)
- [x] Smart workload generator with auto-detection
- [x] Performance visualization
- [x] C++ hook analysis (mock data ready)
- [x] ROI calculator
- [x] Prometheus metrics exporter

### Phase 2: Real Profiling Integration
- [ ] Milvus with C++ profiling hooks
- [ ] Real FAISS scan_codes timing capture
- [ ] Hardware performance counters
- [ ] Power consumption metrics

### Phase 3: DBPU Prototype
- [ ] FPGA/ASIC prototype integration
- [ ] Hardware-accelerated scan_codes
- [ ] End-to-end latency measurements
- [ ] Production deployment testing

### Phase 4: Production Ready
- [ ] Customer pilots
- [ ] Grafana dashboards
- [ ] Automated CI/CD benchmarking
- [ ] Performance regression detection

---

## ğŸ¤ Contributing

This is a proprietary repository for DataStream Inc. Internal contributors should:
1. Create feature branches from `main`
2. Add comprehensive tests for new analyzers
3. Update this README for new tools
4. Use GitHub Desktop or conventional git workflow

---

